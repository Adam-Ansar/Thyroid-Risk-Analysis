{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Analysis of Diabetes Risk in India**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Creating a comprehensive data analysis tool designed to help medical professionals in streamlining data exploration, analysis, and visualisation to analyze impact of behavioural and lifestyle factors on risk of diabetes in young adults of India.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Data source: https://www.kaggle.com/datasets/ankushpanday1/diabetes-in-youth-vs-adult-in-india\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* A jupyter notebook file (Diabetes Risk Analysis (Hackathon1.ipynb) redone to showcase the data analysis and my progress since first project.\n",
        "* A code that helps in conducting descriptive analysis, exploring influence of lifestyle on diabetes outcome.\n",
        ".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Changed the working directory from its current folder to its parent folder\n",
        "* Accessing the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm new directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1 :  Data Extraction, Transformation, and Loading (ETL) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up & Importing Python packages that we will be using in this project to carry out the analysis. For example Numpy to compute numerical operations and handle arrays, Pandas for data manipulation and analysis, Matplotlib, Seaborn and Plotly to create different data visualisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_style('whitegrid')\n",
        "from sklearn.pipeline import Pipeline\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading and Extracting the dataset into a dataframe for data clean, transformation and analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the CSV dataset containing the data collected previously and extracting it into \n",
        "# diabetes_df dataframe using pd.read_csv() function\n",
        " \n",
        "diabetes_df= pd.read_csv('inputs\\thyroid_cancer_risk_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Previewing top 15 entries in dataset to get a general overview of the dataset with .head() method\n",
        "diabetes_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Checking the total number of rows and columns in diabetes_df dataframe using the .shape attribute\n",
        "diabetes_df.shape\n",
        "print(f\"There are {diabetes_df.shape[0]} rows and {diabetes_df.shape[1]} columns in the Diabetes Dataframe.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking information on Index, Column names, Datatypes and Memory used using .info method\n",
        "Dataframe_info= diabetes_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Checking for any duplicate values\n",
        "duplicates_check= diabetes_df.duplicated().any()\n",
        "print (f'Any duplicate values:',duplicates_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking for missing values in  dataset\n",
        "missingvalues_check= diabetes_df.isnull().dropna().any()\n",
        "missingvalues_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creating a dictionary of columns and their respective unique values\n",
        "\n",
        "unique_values = {\n",
        "    'Age' : diabetes_df['Age'].unique().tolist(),\n",
        "    'Gender': diabetes_df['Gender'].unique().tolist(),\n",
        "    'Region': diabetes_df['Region'].unique().tolist(),\n",
        "    'Physical_Activity_Level': diabetes_df['Physical_Activity_Level'].unique().tolist(),\n",
        "    'Dietary_Habits': diabetes_df['Dietary_Habits'].unique().tolist(),\n",
        "    'Alcohol_Consumption': diabetes_df['Alcohol_Consumption'].unique().tolist(),\n",
        "    'Smoking': diabetes_df['Smoking'].unique().tolist(),\n",
        "    'Sleep_Hours': diabetes_df['Sleep_Hours'].unique().tolist(),\n",
        "    'Stress_Level' : diabetes_df['Stress_Level'].unique().tolist(),\n",
        "    'Screen_Time': diabetes_df['Screen_Time'].unique().tolist(),\n",
        "}\n",
        "\n",
        "# Converting the dictionary to a DataFrame for better visualization\n",
        "unique_behaviour_df = pd.DataFrame.from_dict(unique_values, orient='index').transpose()\n",
        "\n",
        "# Displaying the unique values of each column in DataFrame\n",
        "unique_behaviour_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying the unique terms for each specified column \n",
        "for column, values in unique_values.items(): \n",
        "    print(f\"Unique values for column '{column}':\") \n",
        "    print(values)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Transformation: cleaning the date for data analysis and visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#As this analysis is focused on lifestyle factors influence on diabetes risk in young popuplation\n",
        "# Dropping data columns not going to be used in further analysis\n",
        "col_dropped= [\n",
        "              'ID',\n",
        "              'Family_Income', \n",
        "              'Family_History_Diabetes',\n",
        "              'Parent_Diabetes_Type', \n",
        "              'Genetic_Risk_Score',\n",
        "              'Prediabetes',\n",
        "              'Diabetes_Type'\n",
        "              ]                               \n",
        "diabetes_df= diabetes_df.drop(columns= col_dropped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predictive analysis based on HbA1c test levels and Fasting Blood Sugar levels\n",
        "\n",
        "# Both tests are used to diagnose diabetes and prediabetes \n",
        "# HbA1c test is done to check average blood sugar levels over the past 3 months, ranges from 4.5 to 6.5 for normal levels, from 5.7 to 6.4 for prediabetes,\n",
        "# 6.5 and above for diabetes\n",
        "\n",
        "# Fasting Blood Sugar test is done to check blood sugar levels after fasting for 8 hours, ranges from 70 to 100 for normal levels, \n",
        "# from 100 to 125 for prediabetes and 126 and above for diabetes\n",
        "\n",
        "# Creating the 'Diabetes_Outcome' column based on both HbA1c and Fasting Blood Sugar levels\n",
        "def determine_outcome(row):\n",
        "    if row['HbA1c'] >= 6.5 or row['Fasting_Blood_Sugar'] >= 126:\n",
        "        return 'Diabetic'\n",
        "    elif (row['HbA1c'] >= 5.7 and row['HbA1c'] < 6.5) or (row['Fasting_Blood_Sugar'] >= 100 and row['Fasting_Blood_Sugar'] < 126):\n",
        "        return 'Prediabetic'\n",
        "    else:\n",
        "        return 'Normal'\n",
        "\n",
        "# Apply the function to create the 'Diabetes_Outcome' column\n",
        "diabetes_df['Diabetes_Outcome'] = diabetes_df.apply(determine_outcome, axis=1)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "diabetes_df[['HbA1c', 'Fasting_Blood_Sugar', 'Diabetes_Outcome']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipepline to change category values into numeric values \n",
        "from sklearn.pipeline import Pipeline\n",
        "from category_encoders import OrdinalEncoder\n",
        "\n",
        "# Create the pipeline with ordinal encoder\n",
        "pipeline = Pipeline([\n",
        "    ('ordinal_encoder', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the DataFrame\n",
        "diabetes_clean_df = pipeline.fit_transform(diabetes_df)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "diabetes_clean_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(diabetes_df)\n",
        "\n",
        "# Accessing the OrdinalEncoder instance after fitting\n",
        "encoder = pipeline.named_steps['ordinal_encoder']\n",
        "\n",
        "# Accessing the mappings from the OrdinalEncoder in category_encoders\n",
        "mappings = encoder.mapping\n",
        "\n",
        "# Displaying the mappings for each feature\n",
        "for mapping in mappings:\n",
        "    print(f\"Feature: {mapping['col']}, Mappings: {mapping['mapping']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Cleaning any NAN values\n",
        "diabetes_clean_df= diabetes_clean_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descrpitive Statistics Overview\n",
        "Summary_stats= diabetes_clean_df.describe()\n",
        "\n",
        "Summary_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pipeline functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "   # Correlating data analysis\n",
        "corr_analysis= diabetes_df.corr(method='pearson')\n",
        "corr_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The dataset is too big for project timescope\n",
        "# Randomly selected 500 records\n",
        "\n",
        "diabetes_clean_df = diabetes_clean_df.sample(n=500, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_palette(\"viridis\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "mask = np.zeros_like(corr_analysis, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "sns.heatmap(corr_analysis,annot=True,mask=mask,cmap='viridis',annot_kws={\"size\": 9},linewidths=1.5)\n",
        "plt.ylim(corr_analysis.shape[1],0);\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grouping by 'Age' and 'Gender' and creating a stacked bar plot\n",
        "ax = diabetes_clean_df.groupby(['Age','Gender']).size().unstack().plot(kind='bar', stacked=True)\n",
        "# Setting the legend labels\n",
        "ax.legend(title='Gender', labels=['Male', 'Female', 'Other'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming diabetes_clean_df is your DataFrame\n",
        "# Group by 'Age' and calculate the average Diabetes_Outcome for each gender\n",
        "grouped_data = diabetes_clean_df.groupby(['Age', 'Gender'], as_index=False).agg(AvgOutcome=('Diabetes_Outcome', 'mean'))\n",
        "\n",
        "# Pivot the data to get separate columns for each gender\n",
        "pivot_data = grouped_data.pivot(index='Age', columns='Gender', values='AvgOutcome')\n",
        "\n",
        "# Plot the data\n",
        "pivot_data.plot(kind='line', figsize=(5, 5))\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Average Diabetes Outcome')\n",
        "\n",
        "# Set custom labels for the legend\n",
        "gender_labels = ['Male', 'Female', 'Other']  # Adjust this list as needed depending on your dataset\n",
        "plt.title('Average Diabetes Outcome by Age and Gender')\n",
        "plt.legend(title='Gender', labels=gender_labels)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Scatter plot: Age vs. HbA1c, colored by Gender\n",
        "fig1 = px.scatter(diabetes_clean_df, x='Age', y='HbA1c', color='Gender',\n",
        "                  labels={'Age': 'Age', 'HbA1c': 'HbA1c Level', 'Gender': 'Gender'},\n",
        "                  title='Age vs. HbA1c Levels by Gender')\n",
        "fig1.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Bar Plot: Average BMI by Region\n",
        "fig2 = px.bar(diabetes_clean_df, x='Region', y='BMI', color='Region', \n",
        "              labels={'Region': 'Region', 'BMI': 'Average BMI'},\n",
        "              title='Average BMI by Region', barmode='group')\n",
        "fig2.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create the box plot with jitter and different colors for each level of physical activity\n",
        "\n",
        "fig3 = px.box(diabetes_clean_df, x='Physical_Activity_Level', y='Diabetes_Outcome', \n",
        "              points=\"all\", color='Physical_Activity_Level',\n",
        "              labels={'Physical_Activity_Level': 'Physical Activity Level', 'Diabetes_Outcome': 'Diabetes Outcome'},\n",
        "              title='Diabetes Outcome by Physical Activity Level')\n",
        "\n",
        "# Show the plot\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculating the correlation matrix\n",
        "corr_matrix = diabetes_clean_df.corr()\n",
        "\n",
        "# Creating an annotated heatmap\n",
        "fig4 = go.Figure(data=go.Heatmap(\n",
        "                   z=corr_matrix.values,\n",
        "                   x=corr_matrix.columns,\n",
        "                   y=corr_matrix.index,\n",
        "                   colorscale='Viridis'))\n",
        "\n",
        "# Adding annotations\n",
        "for i in range(len(corr_matrix)):\n",
        "    for j in range(len(corr_matrix)):\n",
        "        fig4.add_annotation(\n",
        "            x=corr_matrix.columns[j],\n",
        "            y=corr_matrix.index[i],\n",
        "            text=str(np.round(corr_matrix.values[i, j], 2)),\n",
        "            showarrow=False,\n",
        "            font=dict(color=\"white\" if corr_matrix.values[i, j] < 0 else \"black\")\n",
        "        )\n",
        "fig4.update_layout(\n",
        "    title='Correlation Heatmap',\n",
        "    xaxis_nticks=36\n",
        ")\n",
        "fig4.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
